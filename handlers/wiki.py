import requests
from bs4 import BeautifulSoup
import re
from aiogram import Router, types, F
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import StatesGroup, State
from aiogram.utils.keyboard import InlineKeyboardBuilder

router = Router()

class WikiStates(StatesGroup):
    waiting_for_query = State()

# –ó–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ –±—Ä–∞—É–∑–µ—Ä–∞
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36'
}

def clean_text(text):
    """–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –æ—Ç –º—É—Å–æ—Ä–∞ –≤–∏–∫–∏-—Ä–∞–∑–º–µ—Ç–∫–∏"""
    text = re.sub(r'\[.*?\]', '', text) # –£–±–∏—Ä–∞–µ–º [1], [–ø—Ä–∞–≤–∏—Ç—å]
    text = text.replace('–ø—Ä–∞–≤–∏—Ç—å', '').replace('–ø—Ä–∞–≤–∏—Ç—å –∫–æ–¥', '')
    return " ".join(text.split())

@router.callback_query(F.data == "m_wiki")
async def wiki_start(callback: types.CallbackQuery, state: FSMContext):
    await state.set_state(WikiStates.waiting_for_query)
    await callback.message.answer("üîç <b>–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –¢–µ—Ä—Ä–∞—Ä–∏–∏ (Wiki.gg)</b>\n\n–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–µ–¥–º–µ—Ç–∞, –±–æ—Å—Å–∞ –∏–ª–∏ –º–æ–±–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º:")

@router.message(WikiStates.waiting_for_query)
async def wiki_fetch(message: types.Message, state: FSMContext):
    user_query = message.text.strip()
    msg = await message.answer("üì° <i>–°—á–∏—Ç—ã–≤–∞—é –∞—Ä—Ö–∏–≤—ã...</i>", parse_mode="HTML")
    
    api_url = "https://terraria.wiki.gg/ru/api.php"
    
    try:
        # 1. –ò—Å–ø–æ–ª—å–∑—É–µ–º API –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ (extract)
        # –≠—Ç–æ —Å–∞–º—ã–π –Ω–∞–¥–µ–∂–Ω—ã–π —Å–ø–æ—Å–æ–± –ø–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—Å—Ç –±–µ–∑ –º—É—Å–æ—Ä–∞
        params = {
            "action": "query",
            "format": "json",
            "prop": "extracts|pageimages",
            "exintro": True,      # –¢–æ–ª—å–∫–æ –≤—Å—Ç—É–ø–ª–µ–Ω–∏–µ
            "explaintext": True,  # –¢–æ–ª—å–∫–æ —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ HTML
            "titles": user_query,
            "redirects": 1,       # –ê–≤—Ç–æ-–ø–µ—Ä–µ—Ö–æ–¥ (–ø–ª–∞–Ω—Ç–µ—Ä–∞ -> –ü–ª–∞–Ω—Ç–µ—Ä–∞)
            "piprop": "original"
        }
        
        response = requests.get(api_url, params=params, headers=HEADERS, timeout=10).json()
        pages = response.get("query", {}).get("pages", {})
        page_id = list(pages.keys())[0]

        # –ï—Å–ª–∏ –ø–æ –ø—Ä—è–º–æ–º—É –Ω–∞–∑–≤–∞–Ω–∏—é –Ω–µ –Ω–∞—à–ª–∏, –ø—Ä–æ–±—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫
        if page_id == "-1":
            search_params = {
                "action": "query",
                "list": "search",
                "srsearch": user_query,
                "format": "json",
                "srlimit": 1
            }
            s_res = requests.get(api_url, params=search_params, headers=HEADERS).json()
            if s_res.get("query", {}).get("search"):
                user_query = s_res["query"]["search"][0]["title"]
                # –ü–æ–≤—Ç–æ—Ä—è–µ–º –∑–∞–ø—Ä–æ—Å —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ç–∏—Ç—É–ª–æ–º
                params["titles"] = user_query
                response = requests.get(api_url, params=params, headers=HEADERS).json()
                pages = response.get("query", {}).get("pages", {})
                page_id = list(pages.keys())[0]

        if page_id == "-1":
            await msg.edit_text("‚ùå <b>–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.</b> –ü–æ–ø—Ä–æ–±—É–π –¥—Ä—É–≥–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ.")
            await state.clear()
            return

        page_data = pages[page_id]
        title = page_data.get("title", "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
        description = page_data.get("extract", "")

        # 2. –ü–æ–ª—É—á–∞–µ–º –∫–∞—Ä—Ç–∏–Ω–∫—É (—á–µ—Ä–µ–∑ BeautifulSoup, —Ç–∞–∫ –∫–∞–∫ API –∏–Ω–æ–≥–¥–∞ –∂–∞–¥–Ω–∏—á–∞–µ—Ç)
        img_url = None
        # –ü—Ä–æ–±—É–µ–º –≤–∑—è—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É –∏–∑ API
        if "original" in page_data:
            img_url = page_data["original"].get("source")
        
        # –ï—Å–ª–∏ API –Ω–µ –¥–∞–ª–æ –∫–∞—Ä—Ç–∏–Ω–∫—É, –∏–¥–µ–º –ø–∞—Ä—Å–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É
        if not img_url:
            page_url = f"https://terraria.wiki.gg/ru/wiki/{title.replace(' ', '_')}"
            soup_res = requests.get(page_url, headers=HEADERS)
            soup = BeautifulSoup(soup_res.text, 'lxml')
            
            # –ò—â–µ–º –≤ –∏–Ω—Ñ–æ–±–æ–∫—Å–µ
            aside = soup.find('aside') or soup.find('table', class_='infobox')
            if aside:
                img_tag = aside.find('img')
                if img_tag:
                    img_url = img_tag.get('src')
                    if img_url and img_url.startswith('/'):
                        img_url = "https://terraria.wiki.gg" + img_url

        # 3. –ï—Å–ª–∏ API –≤—ã–¥–∞–ª–æ –ø—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç, –ø—Ä–∏–º–µ–Ω—è–µ–º –ø–∞—Ä—Å–∏–Ω–≥ ¬´–ü–ª–∞–Ω –ë¬ª
        if len(description) < 20:
            page_url = f"https://terraria.wiki.gg/ru/wiki/{title.replace(' ', '_')}"
            soup_res = requests.get(page_url, headers=HEADERS)
            soup = BeautifulSoup(soup_res.text, 'lxml')
            content = soup.find('div', class_='mw-parser-output')
            if content:
                # –£–¥–∞–ª—è–µ–º —Ç–∞–±–ª–∏—Ü—ã –∏ –∏–Ω—Ñ–æ–±–æ–∫—Å—ã
                for junk in content.find_all(['table', 'aside', 'div']):
                    junk.decompose()
                paragraphs = content.find_all('p')
                description = ""
                for p in paragraphs:
                    txt = clean_text(p.text)
                    if len(txt) > 40:
                        description += txt + "\n\n"
                    if len(description) > 800: break

        # –û–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω–∞—è —Å–±–æ—Ä–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è
        if not description:
            description = "–û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –Ω–æ –ø—Ä–µ–¥–º–µ—Ç —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ –±–∞–∑–µ."

        builder = InlineKeyboardBuilder().row(types.InlineKeyboardButton(text="üè† –ú–µ–Ω—é", callback_data="to_main"))
        caption = f"üìñ <b>{title.upper()}</b>\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n{description[:900]}"

        if img_url:
            await message.answer_photo(photo=img_url, caption=caption[:1024], reply_markup=builder.as_markup(), parse_mode="HTML")
        else:
            await message.answer(caption[:4096], reply_markup=builder.as_markup(), parse_mode="HTML")
            
        await msg.delete()

    except Exception as e:
        await msg.edit_text(f"‚ö†Ô∏è <b>–û—à–∏–±–∫–∞:</b> {str(e)}")
    
    await state.clear()
