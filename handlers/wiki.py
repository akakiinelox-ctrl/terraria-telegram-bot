import requests
from bs4 import BeautifulSoup
import re
from aiogram import Router, types, F
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import StatesGroup, State
from aiogram.utils.keyboard import InlineKeyboardBuilder

router = Router()

class WikiStates(StatesGroup):
    waiting_for_query = State()

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36'
}

def clean_text(text):
    # –£–±–∏—Ä–∞–µ–º [1], [–ø—Ä–∞–≤–∏—Ç—å] –∏ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    text = re.sub(r'\[.*?\]', '', text)
    text = text.replace('–ø—Ä–∞–≤–∏—Ç—å', '').replace('–ø—Ä–∞–≤–∏—Ç—å –∫–æ–¥', '')
    return " ".join(text.split())

@router.callback_query(F.data == "m_wiki")
async def wiki_start(callback: types.CallbackQuery, state: FSMContext):
    await state.set_state(WikiStates.waiting_for_query)
    await callback.message.answer("üîç <b>–ü–æ–∏—Å–∫ –ø–æ Wiki.gg / Fandom</b>\n\n–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä: <i>–ü–ª–∞–Ω—Ç–µ—Ä–∞, –ó–µ–Ω–∏—Ç, –ú—É—Ä–∞–º–∞—Å–∞</i>):", parse_mode="HTML")

@router.message(WikiStates.waiting_for_query)
async def wiki_fetch(message: types.Message, state: FSMContext):
    user_query = message.text.strip()
    msg = await message.answer("üì° <i>–°—á–∏—Ç—ã–≤–∞—é –¥–∞–Ω–Ω—ã–µ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã...</i>", parse_mode="HTML")
    
    # –°–Ω–∞—á–∞–ª–∞ –Ω–∞–π–¥–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π URL —á–µ—Ä–µ–∑ –ø–æ–∏—Å–∫
    search_url = "https://terraria.fandom.com/ru/api.php"
    search_params = {
        "action": "query",
        "list": "search",
        "srsearch": user_query,
        "format": "json",
        "srlimit": 1
    }

    try:
        s_res = requests.get(search_url, params=search_params, headers=HEADERS).json()
        if not s_res.get("query", {}).get("search"):
            await msg.edit_text("‚ùå <b>–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.</b>")
            return

        title = s_res["query"]["search"][0]["title"]
        url = f"https://terraria.fandom.com/ru/wiki/{title.replace(' ', '_')}"
        
        # –ó–ê–ì–†–£–ñ–ê–ï–ú –°–¢–†–ê–ù–ò–¶–£ –ü–û–õ–ù–û–°–¢–¨–Æ
        page_res = requests.get(url, headers=HEADERS)
        page_res.encoding = 'utf-8'
        soup = BeautifulSoup(page_res.text, 'lxml')

        # 1. –ò—â–µ–º –∫–∞—Ä—Ç–∏–Ω–∫—É –≤ –∏–Ω—Ñ–æ–±–æ–∫—Å–µ
        img_url = None
        aside = soup.find('aside') or soup.find('table', class_='infobox')
        if aside:
            img_tag = aside.find('img')
            if img_tag:
                img_url = img_tag.get('src')
                if img_url.startswith('//'): img_url = "https:" + img_url

        # 2. –ò—â–µ–º —Ç–µ–∫—Å—Ç (–ü—Ä—è–º–æ–π –ø–∞—Ä—Å–∏–Ω–≥ HTML)
        description = ""
        content = soup.find('div', class_='mw-parser-output')
        
        if content:
            # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã, –∫–æ—Ç–æ—Ä—ã–µ –ù–ï –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ —Ç–∞–±–ª–∏—Ü –∏–ª–∏ –∏–Ω—Ñ–æ–±–æ–∫—Å–æ–≤
            paragraphs = content.find_all('p', recursive=False)
            
            # –ï—Å–ª–∏ –Ω–∞ –≤–µ—Ä—Ö–Ω–µ–º —É—Ä–æ–≤–Ω–µ –Ω–µ—Ç <p>, –∏—â–µ–º –ø–æ –≤—Å–µ–π —Å—Ç–∞—Ç—å–µ, –Ω–æ –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –¥–ª–∏–Ω–Ω—ã–π
            if not paragraphs:
                paragraphs = content.find_all('p')

            for p in paragraphs:
                txt = clean_text(p.text)
                if len(txt) > 50: # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π –∞–±–∑–∞—Ü
                    description = txt
                    break
        
        if not description:
            description = "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç. –°—Ç—Ä–∞–Ω–∏—Ü–∞ —Å–ª–∏—à–∫–æ–º —Å–ª–æ–∂–Ω–∞—è –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —á—Ç–µ–Ω–∏—è."

        builder = InlineKeyboardBuilder().row(types.InlineKeyboardButton(text="üè† –ú–µ–Ω—é", callback_data="to_main"))
        caption = f"üìñ <b>{title.upper()}</b>\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n{description[:900]}"

        if img_url:
            await message.answer_photo(photo=img_url, caption=caption[:1024], reply_markup=builder.as_markup(), parse_mode="HTML")
        else:
            await message.answer(caption[:4096], reply_markup=builder.as_markup(), parse_mode="HTML")
        
        await msg.delete()

    except Exception as e:
        await msg.edit_text(f"‚ö†Ô∏è –û—à–∏–±–∫–∞: {e}")
    
    await state.clear()
